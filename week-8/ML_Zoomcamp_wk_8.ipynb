{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada72d65",
   "metadata": {},
   "source": [
    "## Import Packages and Data Loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b26e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1546cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 01:31:38.830386: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd5a71f",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a344328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to create a CNN model\n",
    "def createModel():\n",
    "    # Create the CNN model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3), activation='relu'))\n",
    "\n",
    "    # Max pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Flatten layer\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Dense layer with 64 neurons\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "\n",
    "    # Output layer with 1 neuron for binary classification\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e5d4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to create an optimizer and compile with that CNN model\n",
    "def initOptimizer(model):\n",
    "    # Compile the model with SGD optimizer\n",
    "    sgd_optimizer = SGD(lr=0.002, momentum=0.8)\n",
    "    model.compile(optimizer=sgd_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc6988a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 01:31:40.644120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-20 01:31:40.651218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-20 01:31:40.651809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-20 01:31:40.652721: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 01:31:40.653043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-20 01:31:40.653607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-20 01:31:40.654122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-20 01:31:41.265794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-20 01:31:41.266386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-20 01:31:41.266955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-20 01:31:41.267518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13795 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Display the model summary\n",
    "model = createModel()\n",
    "model = initOptimizer(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0408a06",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "    mean squared error\n",
    "    binary crossentropy\n",
    "    categorical crossentropy\n",
    "    cosine similarity\n",
    "\n",
    "    Note: since we specify an activation for the output layer, we don't need to set from_logits=True\n",
    "\n",
    "\n",
    "### Answer: binary crossentropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3388d39f",
   "metadata": {},
   "source": [
    "\n",
    "### Question 2\n",
    "\n",
    "What's the number of parameters in the convolutional layer of our model? You can use the summary method for that.\n",
    "\n",
    "    1\n",
    "    65\n",
    "    896\n",
    "    11214912\n",
    "    \n",
    "### Answer: 11214912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37380f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 01:31:42.846804: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-11-20 01:31:43.488294: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-20 01:31:43.488972: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-20 01:31:43.489007: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-11-20 01:31:43.489479: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-20 01:31:43.489551: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 11s 48ms/step - loss: 0.6604 - accuracy: 0.5953 - val_loss: 0.5968 - val_accuracy: 0.6765\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.5903 - accuracy: 0.6908 - val_loss: 0.5663 - val_accuracy: 0.6961\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.5501 - accuracy: 0.7278 - val_loss: 0.5369 - val_accuracy: 0.7473\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.5089 - accuracy: 0.7648 - val_loss: 0.5225 - val_accuracy: 0.7636\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.4833 - accuracy: 0.7716 - val_loss: 0.5143 - val_accuracy: 0.7505\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.4711 - accuracy: 0.7884 - val_loss: 0.5118 - val_accuracy: 0.7397\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.4461 - accuracy: 0.8123 - val_loss: 0.4862 - val_accuracy: 0.7734\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.4131 - accuracy: 0.8189 - val_loss: 0.4913 - val_accuracy: 0.7636\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 9s 48ms/step - loss: 0.3872 - accuracy: 0.8306 - val_loss: 0.4989 - val_accuracy: 0.7636\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.3660 - accuracy: 0.8523 - val_loss: 0.4827 - val_accuracy: 0.7691\n",
      "Median of training accuracy: 0.7799836993217468\n",
      "Standard deviation of training loss: 0.08785606773341634\n"
     ]
    }
   ],
   "source": [
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Define the train and test generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './data/train/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    './data/test/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Train the model and collect metrics\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")\n",
    "\n",
    "# Calculate median of training accuracy and standard deviation of training loss\n",
    "median_train_accuracy = np.median(history.history['accuracy'])\n",
    "std_dev_train_loss = np.std(history.history['loss'])\n",
    "\n",
    "print(f\"Median of training accuracy: {median_train_accuracy}\")\n",
    "print(f\"Standard deviation of training loss: {std_dev_train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6560d875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of training accuracy: 0.78\n",
      "Standard deviation of training loss: 0.088\n"
     ]
    }
   ],
   "source": [
    "print(f\"Median of training accuracy: {round(median_train_accuracy,2)}\")\n",
    "print(f\"Standard deviation of training loss: {round(std_dev_train_loss,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1630c98",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "    0.20\n",
    "    0.40\n",
    "    0.60\n",
    "    0.80\n",
    "\n",
    "### Answer:  0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c396d3b",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "    0.031\n",
    "    0.061\n",
    "    0.091\n",
    "    0.131\n",
    "    \n",
    "### Answer: 0.091"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ac8e73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.3335 - accuracy: 0.8640 - val_loss: 0.5329 - val_accuracy: 0.7582\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.2899 - accuracy: 0.8975 - val_loss: 0.6221 - val_accuracy: 0.7059\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 9s 46ms/step - loss: 0.2558 - accuracy: 0.9094 - val_loss: 0.5139 - val_accuracy: 0.7658\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.2189 - accuracy: 0.9285 - val_loss: 0.5394 - val_accuracy: 0.7658\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.1868 - accuracy: 0.9426 - val_loss: 0.5311 - val_accuracy: 0.7636\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.1515 - accuracy: 0.9578 - val_loss: 0.5862 - val_accuracy: 0.7571\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.1334 - accuracy: 0.9646 - val_loss: 0.5739 - val_accuracy: 0.7756\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.1020 - accuracy: 0.9815 - val_loss: 0.6679 - val_accuracy: 0.7614\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.0844 - accuracy: 0.9840 - val_loss: 0.6418 - val_accuracy: 0.7669\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 9s 47ms/step - loss: 0.0705 - accuracy: 0.9880 - val_loss: 0.6937 - val_accuracy: 0.7767\n"
     ]
    }
   ],
   "source": [
    "# Data generators with augmentations\n",
    "train_datagen_augmented = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen_augmented = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Define the train and test generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './data/train/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    './data/test/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Continue training with data augmentations\n",
    "history_augmented = model.fit(\n",
    "    train_generator,  # Use the generator with augmentations\n",
    "    epochs=20,        # Train for 10 more epochs\n",
    "    validation_data=test_generator,\n",
    "    initial_epoch=10  # Start from the last epoch of the previous training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "833fbcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of training accuracy: 0.9502311646938324\n",
      "Standard deviation of training loss: 0.08548457320807519\n"
     ]
    }
   ],
   "source": [
    "# Calculate median of training accuracy and standard deviation of training loss\n",
    "median_train_accuracy_aug = np.median(history_augmented.history['accuracy'])\n",
    "std_dev_train_loss_aug = np.std(history_augmented.history['loss'])\n",
    "\n",
    "print(f\"Median of training accuracy: {median_train_accuracy_aug}\")\n",
    "print(f\"Standard deviation of training loss: {std_dev_train_loss_aug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff5794d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of test loss for all epochs with augmentations: 0.59\n",
      "Average of test accuracy for the last 5 epochs with augmentations: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of test loss for all epochs\n",
    "mean_test_loss_augmented = np.mean(history_augmented.history['val_loss'])\n",
    "\n",
    "# Calculate the average of test accuracy for the last 5 epochs\n",
    "avg_test_accuracy_last_5_epochs_augmented = np.mean(history_augmented.history['val_accuracy'][-5:])\n",
    "\n",
    "print(f\"Mean of test loss for all epochs with augmentations: {round(mean_test_loss_augmented,2)}\")\n",
    "print(f\"Average of test accuracy for the last 5 epochs with augmentations: {round(avg_test_accuracy_last_5_epochs_augmented,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3659d68",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "\n",
    "    Note: make sure you don't re-create the model - we want to continue training the model we already started training.\n",
    "\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "    0.18\n",
    "    0.48\n",
    "    0.78\n",
    "    0.108\n",
    "\n",
    "### Answer: 0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db57f0",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
    "\n",
    "    0.38\n",
    "    0.58\n",
    "    0.78\n",
    "    0.98\n",
    "\n",
    "### Answer: 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13f3bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
